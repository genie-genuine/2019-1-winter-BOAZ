{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 보아즈 카페 시각화 프로젝트\n",
    "\n",
    "### 크롤링 결과에 대한 간단한 설명  \n",
    " - 보아즈 게시물과 전,현기수의 정보를 크롤링\n",
    " - 주로 활용한 변수는 a,b,c 이고, ~~하게 크롤링을 진행하였음 (실제로 진행할 때에는 변수명이 하는 일에 맞게 변수명을 작명해주세요!)\n",
    " \n",
    "### 사용할 시각화 툴 및 구상한 시각화 설명\n",
    " - ggplot2와 R샤이니를 사용해 인터렉티브한 시각화를 할 예정\n",
    " - a 피쳐(열)와 b 피쳐를 활용해 어떤 시각화를 할 예정임"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Module Imoport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#module importing\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Crawler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#네이버 크롤링\n",
    "#활용변수 naver_top20, naver_blog, naver_cafe, naver_news\n",
    "\n",
    "#네이버 \n",
    "url = \"https://www.naver.com\"\n",
    "response = requests.get(url)\n",
    "html = response.text\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "naver = soup.find_all('span', {'class' : 'ah_k'})\n",
    "naver_top20 = [i.text for i in naver][0:20]\n",
    "\n",
    "url = 'https://search.naver.com/search.naver?where={}&sm=tab_jum&query={}'.format(naver_top20[i])\n",
    "response = requests.get(url)\n",
    "html = response.text\n",
    "soup = BeautifulSoup(html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Create DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'naver_top20' : naver_top20, 'rank' : range(1,21)})\n",
    "df['blog'] = naver_blog\n",
    "df['cafe'] = naver_cafe\n",
    "df['news'] = naver_news"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 전체 코드\n",
    "(전체적인 주석을 봐주세요!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1.module importing\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "#2.네이버 크롤링\n",
    "#활용변수 naver_top20, naver_blog, naver_cafe, naver_news\n",
    "\n",
    "#네이버 html가져오기\n",
    "url = \"https://www.naver.com\"\n",
    "response = requests.get(url)\n",
    "html = response.text\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "#naver_top20을 생성 (1등부터 20등)\n",
    "naver = soup.find_all('span', {'class' : 'ah_k'})\n",
    "naver_top20 = [i.text for i in naver][0:20]\n",
    "\n",
    "#네이버 실검 1등~20등 html가져오기\n",
    "url = 'https://search.naver.com/search.naver?where={}&sm=tab_jum&query={}'.format(naver_top20[i])\n",
    "response = requests.get(url)\n",
    "html = response.text\n",
    "soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "#3.Create DataFrame\n",
    "df = pd.DataFrame({'naver_top20' : naver_top20, 'rank' : range(1,21)})\n",
    "df['blog'] = naver_blog\n",
    "df['cafe'] = naver_cafe\n",
    "df['news'] = naver_news"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
